{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "✔ ggplot2 3.2.1     ✔ purrr   0.3.3\n",
      "✔ tibble  2.1.3     ✔ dplyr   0.8.3\n",
      "✔ tidyr   1.0.0     ✔ stringr 1.4.0\n",
      "✔ readr   1.3.1     ✔ forcats 0.4.0\n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "Loading required package: magrittr\n",
      "\n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    set_names\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "Attaching package: ‘MASS’\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "Attaching package: ‘scales’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    discard\n",
      "\n",
      "The following object is masked from ‘package:readr’:\n",
      "\n",
      "    col_factor\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "Attaching package: ‘caret’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: ‘randomForest’\n",
      "\n",
      "The following object is masked from ‘package:ranger’:\n",
      "\n",
      "    importance\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    margin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(\"tidyverse\")\n",
    "library(\"phyloseq\")\n",
    "library('qiime2R')\n",
    "library(\"ggpubr\")\n",
    "library(\"MASS\")\n",
    "library(\"scales\")\n",
    "library(\"caret\")\n",
    "library(\"AppliedPredictiveModeling\")\n",
    "library(\"ranger\")\n",
    "library(\"e1071\")\n",
    "library(\"randomForest\")\n",
    "library(\"alluvial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup, Functions, and loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for analysis\n",
    "set.seed(10031993)\n",
    "# Theme, color palette, and working directory\n",
    "theme_set(theme_pubr())\n",
    "zoe_palette <- c(\"gray\",\"#1b9e77\", \"#7570b3\",  \"#e6ab02\")\n",
    "\n",
    "# Function to return metadata df from phyloseq object\n",
    "pssd2veg <- function(physeq) {\n",
    "  # From a phyloseq object return a dataframe of the sample metadata for use in vegan\n",
    "  # From: https://jacobrprice.github.io/2017/08/26/phyloseq-to-vegan-and-back.html\n",
    "  sd <- sample_data(physeq)\n",
    "  return(as(sd,\"data.frame\"))\n",
    "}\n",
    "# Function to plot or run a linear model on a ASV from a phyloseq object\n",
    "plot_deseq2_DiffAbunMicob <- function(physeq_obj, ASV_number){\n",
    "  temp_sample_tab <- pssd2veg(physeq_obj)\n",
    "  otu_matrix <- as(otu_table(physeq_obj), \"matrix\")\n",
    "  TEMP <- data.frame(ASV_count = otu_matrix[ASV_number,])\n",
    "  TEMP2<- cbind(temp_sample_tab, TEMP)\n",
    "  #Anova(lm(ASV_count ~ Tissue*Rootstock + Tissue*Irrigation + Rootstock*Irrigation + Block, data = TEMP2), type = \"III\")\n",
    "  ggplot(TEMP2, aes(Tissue, ASV_count, fill= Rootstock)) + geom_boxplot(outlier.shape = NA) + geom_point(position = position_jitterdodge(jitter.width = 0.2)) + scale_fill_manual(name = \"Rootstock\", values=zoe_palette) + scale_y_continuous(name=\"Abundance\") + xlab(\"Tissue\") + theme(legend.position=\"right\", axis.title = element_text(size = 14), axis.text = element_text(size = 12), plot.title = element_text(size=22))\n",
    "}\n",
    "\n",
    "# Function to plot confusion matrix using ggtile plot from a confussion matrix object\n",
    "# By user: Enrique P?rez Herrero \n",
    "# on https://stackoverflow.com/questions/46063234/how-to-produce-a-confusion-matrix-and-find-the-misclassification-rate-of-the-na%C3%AF\n",
    "ggplotConfusionMatrix <- function(m){\n",
    "  mytitle <- paste(\"Accuracy\", percent_format()(m$overall[1]),\n",
    "                   \"Kappa\", percent_format()(m$overall[2]))\n",
    "  \n",
    "  d <- as.data.frame.matrix(m$table)\n",
    "  drn <- colnames(d)\n",
    "  drr <- rownames(d)\n",
    "  drs <- rowSums(d)\n",
    "  d <- d %>% mutate_if(is.numeric, funs(./drs))\n",
    "  d <- d %>% gather(x, value)\n",
    "  Y <- cbind(as.data.frame(m$table), Proportion = d$value)\n",
    "\n",
    "  p <-\n",
    "    ggplot(data = Y, aes(x = Reference, y = Prediction, fill= Proportion)) +\n",
    "    geom_tile( colour = \"white\") +\n",
    "    scale_fill_gradient(low = \"white\", high = \"#14A02E\", na.value = \"white\", limits=c(0,1)) +\n",
    "    ggtitle(mytitle) +\n",
    "    # ADDED LINE HERE FOR ANGLE OF X AXIS LABELS\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n",
    "    theme(legend.position = \"right\") +\n",
    "    guides(fill = guide_colorbar(frame.colour = \"black\", ticks = FALSE))\n",
    "  return(p)\n",
    "}\n",
    "\n",
    "MachineLearning_RF_ranger <- function(PHYSEQ_OBJ_1, PHYSEQ_OBJ_2 = FALSE, GROUPING, NUM_TREES = 101) {\n",
    "  if (missing(PHYSEQ_OBJ_2)){\n",
    "    # Remove ASV Table and meta data from phyloseq objects\n",
    "    # 16s\n",
    "    ASV.df <- as.data.frame(otu_table(PHYSEQ_OBJ_1))\n",
    "    ASV_metadata.df <- as.data.frame(sample_data(PHYSEQ_OBJ_1))\n",
    "    # Format ASV table to be used for machine learning applications and make metadata df\n",
    "    ASV.df <- t(ASV.df)\n",
    "    ASV_meta.df <- data.frame(Sample = rownames(ASV_metadata.df), Rootstock = ASV_metadata.df$Rootstock, Tissue = ASV_metadata.df$Tissue, Tissue_Rootstock = paste(ASV_metadata.df$Tissue, ASV_metadata.df$Rootstock, sep = \"_\"))\n",
    "    ASV_prefiltered.df <- cbind(ASV.df, ASV_meta.df)\n",
    "    # ~80:20 split train/test datasets while respecting groups (i.e. sampling the same number of samples from each label)\n",
    "    # 47 berry, leaf, root, and soil samples\n",
    "    if ((GROUPING) == \"Tissue_Rootstock\"){\n",
    "      train_index <- as.data.frame(ASV_prefiltered.df %>% group_by_(GROUPING) %>% sample_n(9))\n",
    "    } else {\n",
    "      train_index <- as.data.frame(ASV_prefiltered.df %>% group_by_(GROUPING) %>% sample_n(36))\n",
    "    }\n",
    "    rownames(train_index) <- train_index$Sample\n",
    "    train_index <- match(rownames(train_index), rownames(ASV_prefiltered.df))\n",
    "    train_x <- as.data.frame(ASV.df[train_index, ])\n",
    "    test_y <- as.data.frame(ASV.df[-train_index, ])\n",
    "    # Train set, 144 samples\n",
    "    train_x$Sample <- rownames(train_x)\n",
    "    Training_meta.df <- merge(train_x, ASV_meta.df, by = 'Sample')\n",
    "    train_x <- subset(Training_meta.df, select = -c(Rootstock, Tissue, Tissue_Rootstock))\n",
    "    rownames(train_x) <- train_x$Sample\n",
    "    train_x <- subset(train_x, select = -c(Sample))\n",
    "    Training_meta.df <- subset(Training_meta.df, select = c(Sample, Rootstock, Tissue, Tissue_Rootstock))\n",
    "    rownames(Training_meta.df) <- Training_meta.df$Sample \n",
    "    # Test set, 40 samples\n",
    "    test_y$Sample <- rownames(test_y)\n",
    "    Testing_meta.df <- merge(test_y, ASV_meta.df, by = \"Sample\")\n",
    "    test_y <- subset(Testing_meta.df, select = -c(Rootstock, Tissue, Tissue_Rootstock))\n",
    "    rownames(test_y) <- test_y$Sample\n",
    "    test_y <- subset(test_y, select = -c(Sample))\n",
    "    Testing_meta.df <- subset(Testing_meta.df, select = c(Sample, Rootstock, Tissue, Tissue_Rootstock))\n",
    "    rownames(Testing_meta.df) <- Testing_meta.df$Sample \n",
    "    # Training model\n",
    "    Training_grid <- expand.grid(.mtry = seq(10, length(train_x), round(length(train_x)*0.1)), .splitrule= \"gini\", .min.node.size = c(1, 5, 10))\n",
    "    RF_CM <- list()\n",
    "    RF_CM[[\"RF_model\"]] <- train(x = train_x, y = Training_meta.df[[GROUPING]], method = \"ranger\", importance = \"impurity\", tuneGrid = Training_grid, num.trees = NUM_TREES)\n",
    "    RF_prediction_3 <- predict(RF_CM[[\"RF_model\"]], test_y)\n",
    "    RF_CM[[\"CMatrix\"]] <- confusionMatrix(RF_prediction_3, as.factor(Testing_meta.df[[GROUPING]]))\n",
    "    RF_CM[[\"CMatrixPLOT\"]] <- ggplotConfusionMatrix(RF_CM[[\"CMatrix\"]])\n",
    "    RF_CM[[\"VarImporance\"]] <- varImp(RF_CM[[\"RF_model\"]], scale = FALSE)\n",
    "    RF_CM\n",
    "  } else {\n",
    "    # Remove ASV Table and meta data from phyloseq objects\n",
    "    # 16s\n",
    "    ASV_16s.df <- as.data.frame(otu_table(PHYSEQ_OBJ_1))\n",
    "    ASV_16s_metadata.df <- as.data.frame(sample_data(PHYSEQ_OBJ_1))\n",
    "    # its\n",
    "    ASV_its.df <- as.data.frame(otu_table(PHYSEQ_OBJ_2))\n",
    "    ASV_its_metadata.df <- as.data.frame(sample_data(PHYSEQ_OBJ_2))\n",
    "    # Combine 16s and ITS data into a single matrix and remove samples that are not present both 16s and ITS datasets\n",
    "    setdiff(rownames(t(ASV_16s.df)), rownames(t(ASV_its.df)))\n",
    "    ASV_16s_4removed.df <- subset(ASV_16s.df, select = -c(`MV11.3309C.2-3.S`, `MV14.3309C.2-3.R`, `MV15.1103P.10-11.R`, `MV16.3309C.14-15.S`))\n",
    "    # merge data frames\n",
    "    Merged_16s_its.df <- rbind(ASV_16s_4removed.df, ASV_its.df)\n",
    "    # Format ASV table to be used for machine learning applications and make metadata df\n",
    "    ASV_both.df <- t(Merged_16s_its.df)\n",
    "    ASV_meta.df <- data.frame(Sample = rownames(ASV_its_metadata.df), Rootstock = ASV_its_metadata.df$Rootstock, Tissue = ASV_its_metadata.df$Tissue, Tissue_Rootstock = paste(ASV_its_metadata.df$Tissue, ASV_its_metadata.df$Rootstock, sep = \"_\"))\n",
    "    ASV_both_w_meta.df <- cbind(ASV_both.df, ASV_meta.df)\n",
    "    # ~80:20 split train/test datasets while respecting groups (i.e. sampling the same number of samples from each label)\n",
    "    # 47 berry, leaf, root, and soil samples\n",
    "    if ((GROUPING) == \"Tissue_Rootstock\"){\n",
    "      train_index <- as.data.frame(ASV_both_w_meta.df %>% group_by_(GROUPING) %>% sample_n(9))\n",
    "    } else {\n",
    "      train_index <- as.data.frame(ASV_both_w_meta.df %>% group_by_(GROUPING) %>% sample_n(36))\n",
    "    }\n",
    "    rownames(train_index) <- train_index$Sample\n",
    "    train_index <- match(rownames(train_index), rownames(ASV_both_w_meta.df))\n",
    "    train_x <- as.data.frame(ASV_both.df[train_index, ])\n",
    "    test_y <- as.data.frame(ASV_both.df[-train_index, ])\n",
    "    # Train set, 144 samples\n",
    "    train_x$Sample <- rownames(train_x)\n",
    "    Training_meta.df <- merge(train_x, ASV_meta.df, by = 'Sample')\n",
    "    train_x <- subset(Training_meta.df, select = -c(Rootstock, Tissue, Tissue_Rootstock))\n",
    "    rownames(train_x) <- train_x$Sample\n",
    "    train_x <- subset(train_x, select = -c(Sample))\n",
    "    Training_meta.df <- subset(Training_meta.df, select = c(Sample, Rootstock, Tissue, Tissue_Rootstock))\n",
    "    rownames(Training_meta.df) <- Training_meta.df$Sample \n",
    "    # Test set, 40 samples\n",
    "    test_y$Sample <- rownames(test_y)\n",
    "    Testing_meta.df <- merge(test_y, ASV_meta.df, by = \"Sample\")\n",
    "    test_y <- subset(Testing_meta.df, select = -c(Rootstock, Tissue, Tissue_Rootstock))\n",
    "    rownames(test_y) <- test_y$Sample\n",
    "    test_y <- subset(test_y, select = -c(Sample))\n",
    "    Testing_meta.df <- subset(Testing_meta.df, select = c(Sample, Rootstock, Tissue, Tissue_Rootstock))\n",
    "    rownames(Testing_meta.df) <- Testing_meta.df$Sample \n",
    "    #Train model predict, and create confusion matrix\n",
    "    Training_grid <- expand.grid(.mtry = seq(10, length(train_x), round(length(train_x)*0.1)), .splitrule= \"gini\", .min.node.size = c(1, 5, 10))\n",
    "    RF_CM <- list()\n",
    "    RF_CM[[\"RF_model\"]] <- train(x = train_x, y = Training_meta.df[[GROUPING]], method = \"ranger\", importance = \"impurity\", tuneGrid = Training_grid, num.trees = NUM_TREES)\n",
    "    RF_prediction_3 <- predict(RF_CM[[\"RF_model\"]], test_y)\n",
    "    RF_CM[[\"CMatrix\"]] <- confusionMatrix(RF_prediction_3, as.factor(Testing_meta.df[[GROUPING]]))\n",
    "    RF_CM[[\"CMatrixPLOT\"]] <- ggplotConfusionMatrix(RF_CM[[\"CMatrix\"]])\n",
    "    RF_CM[[\"VarImporance\"]] <- varImp(RF_CM[[\"RF_model\"]], scale = FALSE)\n",
    "    RF_CM\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physeq_16s <- readRDS(\"physeq_16s.Rds\")\n",
    "physeq_its <- readRDS(\"physeq_its.Rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode factors OWN to Ungrafted\n",
    "physeq_16s@sam_data$Rootstock <- recode_factor(physeq_16s@sam_data$Rootstock , OWN = \"Ungrafted\")\n",
    "physeq_its@sam_data$Rootstock <- recode_factor(physeq_its@sam_data$Rootstock , OWN = \"Ungrafted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“group_by_() is deprecated. \n",
      "Please use group_by() instead\n",
      "\n",
      "The 'programming' vignette or the tidyeval book can help you\n",
      "to program with group_by() : https://tidyeval.tidyverse.org\n",
      "This warning is displayed once per session.”Warning message:\n",
      "“funs() is soft deprecated as of dplyr 0.8.0\n",
      "Please use a list of either functions or lambdas: \n",
      "\n",
      "  # Simple named list: \n",
      "  list(mean = mean, median = median)\n",
      "\n",
      "  # Auto named with `tibble::lst()`: \n",
      "  tibble::lst(mean, median)\n",
      "\n",
      "  # Using lambdas\n",
      "  list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n",
      "This warning is displayed once per session.”"
     ]
    }
   ],
   "source": [
    "##### 1.0 | 16s and ITS data together, 4 samples removed from 16s, and no preprocessing or prefiltering of ASVs. #####\n",
    "RF_1.1 <- MachineLearning_RF_ranger(physeq_16s, physeq_its, GROUPING = \"Rootstock\", NUM_TREES = 314)\n",
    "RF_1.2 <- MachineLearning_RF_ranger(physeq_16s, physeq_its, GROUPING = \"Tissue\", NUM_TREES = 381)\n",
    "RF_1.3 <- MachineLearning_RF_ranger(physeq_16s, physeq_its, GROUPING = \"Tissue_Rootstock\", NUM_TREES = 324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       " 144 samples\n",
       "9394 predictors\n",
       "   4 classes: 'Ungrafted', '1103P', '3309C', 'SO4' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Bootstrapped (25 reps) \n",
       "Summary of sample sizes: 144, 144, 144, 144, 144, 144, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  min.node.size  Accuracy   Kappa       \n",
       "    10   1             0.2179348  -0.014970692\n",
       "    10   5             0.2174720  -0.015595671\n",
       "    10  10             0.2305815   0.001507861\n",
       "   949   1             0.3672886   0.168895941\n",
       "   949   5             0.3578489   0.155622901\n",
       "   949  10             0.3678063   0.169096536\n",
       "  1888   1             0.3799966   0.184979892\n",
       "  1888   5             0.3702900   0.171596647\n",
       "  1888  10             0.3792755   0.183249920\n",
       "  2827   1             0.3787848   0.182121606\n",
       "  2827   5             0.3885524   0.195138466\n",
       "  2827  10             0.3674067   0.167749875\n",
       "  3766   1             0.3750189   0.177053604\n",
       "  3766   5             0.3864066   0.191437046\n",
       "  3766  10             0.3726334   0.174388625\n",
       "  4705   1             0.3831016   0.187667646\n",
       "  4705   5             0.3822467   0.186037532\n",
       "  4705  10             0.3834774   0.186773596\n",
       "  5644   1             0.3718515   0.172639449\n",
       "  5644   5             0.3630576   0.161020392\n",
       "  5644  10             0.3766183   0.177797500\n",
       "  6583   1             0.3731913   0.174356766\n",
       "  6583   5             0.3725792   0.173761497\n",
       "  6583  10             0.3745036   0.177320438\n",
       "  7522   1             0.3731899   0.173807622\n",
       "  7522   5             0.3841751   0.188147093\n",
       "  7522  10             0.3847979   0.189376982\n",
       "  8461   1             0.3806947   0.183951930\n",
       "  8461   5             0.3825836   0.187307327\n",
       "  8461  10             0.3737255   0.174961881\n",
       "\n",
       "Tuning parameter 'splitrule' was held constant at a value of gini\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were mtry = 2827, splitrule = gini\n",
       " and min.node.size = 5."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RF_1.1$RF_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       " 144 samples\n",
       "9394 predictors\n",
       "   4 classes: 'Berry', 'Leaf', 'Root', 'Soil' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Bootstrapped (25 reps) \n",
       "Summary of sample sizes: 144, 144, 144, 144, 144, 144, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  min.node.size  Accuracy   Kappa    \n",
       "    10   1             0.8596497  0.8153643\n",
       "    10   5             0.8636361  0.8206330\n",
       "    10  10             0.8616578  0.8181316\n",
       "   949   1             0.9831600  0.9774230\n",
       "   949   5             0.9854089  0.9804295\n",
       "   949  10             0.9824053  0.9764154\n",
       "  1888   1             0.9800192  0.9732146\n",
       "  1888   5             0.9817036  0.9754713\n",
       "  1888  10             0.9817036  0.9754713\n",
       "  2827   1             0.9815296  0.9752371\n",
       "  2827   5             0.9815543  0.9752830\n",
       "  2827  10             0.9808283  0.9742927\n",
       "  3766   1             0.9784768  0.9711425\n",
       "  3766   5             0.9785565  0.9712243\n",
       "  3766  10             0.9770600  0.9692238\n",
       "  4705   1             0.9738510  0.9649049\n",
       "  4705   5             0.9724134  0.9629239\n",
       "  4705  10             0.9753870  0.9669767\n",
       "  5644   1             0.9698928  0.9595573\n",
       "  5644   5             0.9697856  0.9594119\n",
       "  5644  10             0.9714776  0.9616916\n",
       "  6583   1             0.9710498  0.9611108\n",
       "  6583   5             0.9663460  0.9547734\n",
       "  6583  10             0.9693880  0.9588455\n",
       "  7522   1             0.9657083  0.9539253\n",
       "  7522   5             0.9661898  0.9545731\n",
       "  7522  10             0.9641356  0.9518154\n",
       "  8461   1             0.9616251  0.9484419\n",
       "  8461   5             0.9632165  0.9505777\n",
       "  8461  10             0.9638950  0.9514774\n",
       "\n",
       "Tuning parameter 'splitrule' was held constant at a value of gini\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were mtry = 949, splitrule = gini\n",
       " and min.node.size = 5."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RF_1.2$RF_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       " 144 samples\n",
       "9394 predictors\n",
       "  16 classes: 'Berry_1103P', 'Berry_3309C', 'Berry_SO4', 'Berry_Ungrafted', 'Leaf_1103P', 'Leaf_3309C', 'Leaf_SO4', 'Leaf_Ungrafted', 'Root_1103P', 'Root_3309C', 'Root_SO4', 'Root_Ungrafted', 'Soil_1103P', 'Soil_3309C', 'Soil_SO4', 'Soil_Ungrafted' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Bootstrapped (25 reps) \n",
       "Summary of sample sizes: 144, 144, 144, 144, 144, 144, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  min.node.size  Accuracy   Kappa    \n",
       "    10   1             0.1609761  0.1259447\n",
       "    10   5             0.1584087  0.1241194\n",
       "    10  10             0.1580139  0.1233453\n",
       "   949   1             0.2497978  0.2113840\n",
       "   949   5             0.2428230  0.2035286\n",
       "   949  10             0.2498001  0.2111543\n",
       "  1888   1             0.2473579  0.2083031\n",
       "  1888   5             0.2478270  0.2081808\n",
       "  1888  10             0.2542999  0.2150218\n",
       "  2827   1             0.2613154  0.2220747\n",
       "  2827   5             0.2570167  0.2170257\n",
       "  2827  10             0.2578792  0.2174375\n",
       "  3766   1             0.2667006  0.2270452\n",
       "  3766   5             0.2596218  0.2195708\n",
       "  3766  10             0.2681544  0.2280384\n",
       "  4705   1             0.2641259  0.2242052\n",
       "  4705   5             0.2688250  0.2291181\n",
       "  4705  10             0.2594214  0.2183848\n",
       "  5644   1             0.2591893  0.2191841\n",
       "  5644   5             0.2648121  0.2238523\n",
       "  5644  10             0.2592900  0.2181663\n",
       "  6583   1             0.2707599  0.2303234\n",
       "  6583   5             0.2645848  0.2238911\n",
       "  6583  10             0.2638127  0.2229091\n",
       "  7522   1             0.2625985  0.2221300\n",
       "  7522   5             0.2623021  0.2212413\n",
       "  7522  10             0.2710570  0.2301174\n",
       "  8461   1             0.2575363  0.2159715\n",
       "  8461   5             0.2659650  0.2246719\n",
       "  8461  10             0.2593936  0.2175694\n",
       "\n",
       "Tuning parameter 'splitrule' was held constant at a value of gini\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were mtry = 7522, splitrule = gini\n",
       " and min.node.size = 10."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RF_1.3$RF_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting and saving a object to combine in Rstudio\n",
    "\n",
    "X <- ggarrange(RF_1.1[[3]], RF_1.2[[3]], RF_1.3[[3]], ncol = 3, common.legend = TRUE, legend = \"right\")\n",
    "pdf(\"RF_model_for_plot.pdf\", onefile = TRUE, width = 18, height = 12)\n",
    "print(X)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different datasets across rootstock, tissue, and both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### 1.0 | 16s and ITS data together, 4 samples removed from 16s, and no preprocessing or prefiltering of ASVs. #####\n",
    "# RF_1.1 <- MachineLearning_RF_ranger(physeq_16s, physeq_its, GROUPING = \"Rootstock\")\n",
    "# RF_1.2 <- MachineLearning_RF_ranger(physeq_16s, physeq_its, GROUPING = \"Tissue\")\n",
    "# RF_1.3 <- MachineLearning_RF_ranger(physeq_16s, physeq_its, GROUPING = \"Tissue_Rootstock\")\n",
    "\n",
    "# ##### 2.0 | 16s and ITS data together with prefiltering of ASVs, 4 samples removed from 16s, and no preprocessing. #####\n",
    "# # Filter dataset to eliminate ASVs that are mostly zeros\n",
    "# # Remove taxa that are not found greater than 15 times in 10% of the samples\n",
    "# # 16s: 8199 ASVs => 1084  | ITS: 1195 ASVs => 124\n",
    "# physeq_16s_filtered <- filter_taxa(physeq_16s, function(x) sum(x > 15) > (0.10*length(x)), TRUE)\n",
    "# physeq_its_filtered <- filter_taxa(physeq_its, function(x) sum(x > 15) > (0.10*length(x)), TRUE)\n",
    "# RF_2.1 <- MachineLearning_RF_ranger(physeq_16s_filtered, physeq_its_filtered, GROUPING = \"Rootstock\")\n",
    "# RF_2.2 <- MachineLearning_RF_ranger(physeq_16s_filtered, physeq_its_filtered, GROUPING = \"Tissue\")\n",
    "# RF_2.3 <- MachineLearning_RF_ranger(physeq_16s_filtered, physeq_its_filtered, GROUPING = \"Tissue_Rootstock\")\n",
    "\n",
    "# ##### 3.0 | 16s data, no prefiltering or preprocessing of ASVs. #####\n",
    "# RF_3.1 <- MachineLearning_RF_ranger(physeq_16s, GROUPING = \"Rootstock\")\n",
    "# RF_3.2 <- MachineLearning_RF_ranger(physeq_16s, GROUPING = \"Tissue\")\n",
    "# RF_3.3 <- MachineLearning_RF_ranger(physeq_16s, GROUPING = \"Tissue_Rootstock\")\n",
    "\n",
    "# ##### 4.0 | 16s data, no preprocessing of ASVs. #####\n",
    "# # Filter dataset to eliminate ASVs that are mostly zeros\n",
    "# # Remove taxa that are not found greater than 15 times in 10% of the samples\n",
    "# # 16s: 8199 ASVs => 1084\n",
    "# physeq_16s_filtered <- filter_taxa(physeq_16s, function(x) sum(x > 15) > (0.10*length(x)), TRUE)\n",
    "# RF_4.1 <- MachineLearning_RF_ranger(physeq_16s_filtered, GROUPING = \"Rootstock\")\n",
    "# RF_4.2 <- MachineLearning_RF_ranger(physeq_16s_filtered, GROUPING = \"Tissue\")\n",
    "# RF_4.3 <- MachineLearning_RF_ranger(physeq_16s_filtered, GROUPING = \"Tissue_Rootstock\")\n",
    "\n",
    "# ##### 5.0 | its data, no prefiltering or preprocessing of ASVs. #####\n",
    "# RF_5.1 <- MachineLearning_RF_ranger(physeq_its, GROUPING = \"Rootstock\")\n",
    "# RF_5.2 <- MachineLearning_RF_ranger(physeq_its, GROUPING = \"Tissue\")\n",
    "# RF_5.3 <- MachineLearning_RF_ranger(physeq_its, GROUPING = \"Tissue_Rootstock\")\n",
    "\n",
    "# ##### 6.0 | its data, no preprocessing of ASVs. #####\n",
    "# # Filter dataset to eliminate ASVs that are mostly zeros\n",
    "# # Remove taxa that are not found greater than 15 times in 10% of the samples\n",
    "# # 16s: 8199 ASVs => 1084  | ITS: 1195 ASVs => 124\n",
    "# physeq_its_filtered <- filter_taxa(physeq_its, function(x) sum(x > 15) > (0.10*length(x)), TRUE)\n",
    "# RF_6.1 <- MachineLearning_RF_ranger(physeq_its_filtered, GROUPING = \"Rootstock\")\n",
    "# RF_6.2 <- MachineLearning_RF_ranger(physeq_its_filtered, GROUPING = \"Tissue\")\n",
    "# RF_6.3 <- MachineLearning_RF_ranger(physeq_its_filtered, GROUPING = \"Tissue_Rootstock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving CM's of all datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A <- annotate_figure(ggarrange(RF_1.1[[3]], RF_1.2[[3]], RF_1.3[[3]]), top = text_grob(\"16s and ITS data together, no filtering\", color = \"red\", face = \"bold\", size = 14))\n",
    "# B <- annotate_figure(ggarrange(RF_2.1[[3]], RF_2.2[[3]], RF_2.3[[3]]), top = text_grob(\"16s and ITS data together with prefiltering of ASVs\", color = \"red\", face = \"bold\", size = 14))\n",
    "# C <- annotate_figure(ggarrange(RF_3.1[[3]], RF_3.2[[3]], RF_3.3[[3]]), top = text_grob(\"16s data, no filtering\", color = \"red\", face = \"bold\", size = 14))\n",
    "# D <- annotate_figure(ggarrange(RF_4.1[[3]], RF_4.2[[3]], RF_4.3[[3]]), top = text_grob(\"16s data filtered\", color = \"red\", face = \"bold\", size = 14))\n",
    "# E <- annotate_figure(ggarrange(RF_5.1[[3]], RF_5.2[[3]], RF_5.3[[3]]), top = text_grob(\"ITS data, no filtering\", color = \"red\", face = \"bold\", size = 14))\n",
    "# F <- annotate_figure(ggarrange(RF_6.1[[3]], RF_6.2[[3]], RF_6.3[[3]]), top = text_grob(\"ITS data filtered\", color = \"red\", face = \"bold\", size = 14))\n",
    "# ggarrange(A, B, C, D, E, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_list <- list(A, B, C, D, E, F)\n",
    "# pdf(\"All_RF_models_and_datasets.pdf\", onefile = TRUE, width = 18, height = 12)\n",
    "# print(plot_list)\n",
    "# dev.off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
